{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Documentation\n",
    "\n",
    "> Classes and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "from nbdev.showdoc import *\n",
    "import os\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms, models\n",
    "import torchvision.models as models\n",
    "from torch.utils.tensorboard import SummaryWriter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class FuturamaDataset(Dataset):\n",
    "    \"Pytorch Dataset to process the images and labels.\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                data_path:str, # path to the train.csv\n",
    "                train_images_path:str, # path to the train images\n",
    "                transform:torch.nn.Module=None # transformation \n",
    "        ): \n",
    "        \"FuturamaDataset Initialization\"\n",
    "        \n",
    "        self.data_path = data_path\n",
    "        self.train_images_path = train_images_path\n",
    "        self.data_frame = pd.read_csv(data_path)\n",
    "        self.transform = transform\n",
    "        self.n_samples = len(self.data_frame.index)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.train_images_path, self.data_frame[\"file\"][idx])\n",
    "\n",
    "        image = self.transform(Image.open(img_path).convert(\"RGB\"))\n",
    "\n",
    "        isLeela = self.data_frame[\"isLeela\"][idx]\n",
    "        isFry = self.data_frame[\"isFry\"][idx]\n",
    "        isBender = self.data_frame[\"isBender\"][idx]\n",
    "\n",
    "        sample = {\n",
    "            \"image\": image,\n",
    "            \"labels\": {\"isLeela\": isLeela, \"isFry\": isFry, \"isBender\": isBender},\n",
    "        }\n",
    "        return sample\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "#### FuturamaDataset.__init__\n",
       "\n",
       ">      FuturamaDataset.__init__ (data_path:str, train_images_path:str,\n",
       ">                                transform:torch.nn.modules.module.Module=None)\n",
       "\n",
       "FuturamaDataset Initialization\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| data_path | str |  | path to the train.csv |\n",
       "| train_images_path | str |  | path to the train images |\n",
       "| transform | Module | None | transformation |"
      ],
      "text/plain": [
       "<nbdev.showdoc.BasicMarkdownRenderer>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(FuturamaDataset.__init__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class FuturamaResnet(nn.Module):\n",
    "    \"A resnet adapted to output 3 classes by 3 mlps.\"\n",
    "    def __init__(self, \n",
    "                    resnet_model, # \"resnet152\" or \"resnet34\"\n",
    "                    hidden_mlp, # Numbers of neurons for the hidden layer in each class\n",
    "                    drop_out # Dropout in the hidden layer\n",
    "                    ):\n",
    "        super().__init__()\n",
    "\n",
    "        def mlp(layer_in, hidden, layer_out):\n",
    "            return (\n",
    "                nn.Dropout(p=drop_out),\n",
    "                nn.Linear(layer_in, hidden),\n",
    "                nn.Tanh(),\n",
    "                nn.Linear(hidden, layer_out),\n",
    "            )\n",
    "\n",
    "        if resnet_model == \"resnet152\":\n",
    "            print(\"using resnet152\")\n",
    "\n",
    "            self.resnet = models.resnet152(\n",
    "                weights=torchvision.models.ResNet152_Weights.DEFAULT\n",
    "            )\n",
    "\n",
    "            self.model_wo_fc = nn.Sequential(*(list(self.resnet.children())[:-1]))\n",
    "\n",
    "            self.isLeela = nn.Sequential(\n",
    "                nn.Dropout(p=drop_out), *mlp(2048, hidden_mlp, 2)\n",
    "            )\n",
    "            self.isFry = nn.Sequential(\n",
    "                nn.Dropout(p=drop_out), *mlp(2048, hidden_mlp, 2)\n",
    "            )\n",
    "            self.isBender = nn.Sequential(\n",
    "                nn.Dropout(p=drop_out), *mlp(2048, hidden_mlp, 2)\n",
    "            )\n",
    "        elif resnet_model == \"resnet34\":\n",
    "            print(\"using resnet34\")\n",
    "\n",
    "            self.resnet = models.resnet34(\n",
    "                weights=torchvision.models.ResNet34_Weights.DEFAULT\n",
    "            )\n",
    "\n",
    "            self.model_wo_fc = nn.Sequential(*(list(self.resnet.children())[:-1]))\n",
    "\n",
    "            self.isLeela = nn.Sequential(\n",
    "                nn.Dropout(p=drop_out), *mlp(512, hidden_mlp, 2)\n",
    "            )\n",
    "            self.isFry = nn.Sequential(nn.Dropout(p=drop_out), *mlp(512, hidden_mlp, 2))\n",
    "\n",
    "            self.isBender = nn.Sequential(\n",
    "                nn.Dropout(p=drop_out), *mlp(512, hidden_mlp, 2)\n",
    "            )\n",
    "\n",
    "    def forward(self, x:torch.FloatTensor # input tensor\n",
    "                )->dict: # output a dict with the logs\n",
    "        \"The forward pass of the network.\"\n",
    "        x = self.model_wo_fc(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        return {\n",
    "            \"isLeela\": self.isLeela(x), \n",
    "            \"isFry\": self.isFry(x),\n",
    "            \"isBender\": self.isBender(x),\n",
    "        } \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "#### FuturamaResnet.forward\n",
       "\n",
       ">      FuturamaResnet.forward (x:torch.FloatTensor)\n",
       "\n",
       "The forward pass of the network.\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| x | FloatTensor | input tensor |\n",
       "| **Returns** | **dict** | **output a dict with the logs** |"
      ],
      "text/plain": [
       "<nbdev.showdoc.BasicMarkdownRenderer>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(FuturamaResnet.forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def calc_results(\n",
    "                outputs:dict, #predicted classes\n",
    "                labels:dict  #labels classes\n",
    "                )-> torch.FloatTensor: # Accuracy \n",
    "    \"To calculate the accuracy in validation\"\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        error_class = 0\n",
    "\n",
    "        for key in outputs.keys():\n",
    "            error_class += torch.sum(labels[key] == torch.max(outputs[key], 1)[1])\n",
    "\n",
    "\n",
    "    return error_class\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def criterion(loss_func:nn.CrossEntropyLoss, # Loss function to be used\n",
    "             outputs:dict, # Predicted probs of the classes\n",
    "             pictures:list  # Labels of the classes\n",
    "            )->torch.FloatTensor: # Loss\n",
    "    losses = 0\n",
    "\n",
    "    for key in outputs.keys():\n",
    "\n",
    "        losses += loss_func(outputs[key], pictures[key])\n",
    "\n",
    "    return losses\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def training(\n",
    "            model:nn.Module, #Resnet model to be used.\n",
    "            device:torch.device, #Device to be used to train.\n",
    "            writer:SummaryWriter, #Writer to Tensorboard, can be None\n",
    "            lr_rate:float, #Learning rate\n",
    "            lr_decay:float, #Exponential Decay for the learning rate\n",
    "            epochs:int, #Number of epochs to train\n",
    "            train_loader:DataLoader, #Train data loader\n",
    "            val_loader:DataLoader #Validation data loader\n",
    "):\n",
    "    num_epochs = epochs\n",
    "\n",
    "    epoch_losses_train = []\n",
    "    epoch_losses_test = []\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr_rate)\n",
    "    exp_scheduler = torch.optim.lr_scheduler.ExponentialLR(\n",
    "        optimizer, lr_decay, verbose=True\n",
    "    )\n",
    "    n_total_steps_train = len(train_loader)\n",
    "    n_total_steps_test = len(val_loader)\n",
    "\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        model.train()\n",
    "        losses = []\n",
    "\n",
    "        for i, pictures in enumerate(train_loader):\n",
    "            images = pictures[\"image\"].to(device)\n",
    "            labels = {\n",
    "                    picture:pictures[\"labels\"][picture].to(device)\n",
    "                    for picture in pictures[\"labels\"]\n",
    "                }\n",
    "\n",
    "            outputs = model(images)\n",
    "\n",
    "            loss = criterion(loss_func, outputs, labels)\n",
    "\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        checkpoint_loss = torch.tensor(losses).mean().item()\n",
    "        epoch_losses_train.append(checkpoint_loss)\n",
    "        if writer is not None:\n",
    "            writer.add_scalar(\"Loss/train\", checkpoint_loss, epoch)\n",
    "\n",
    "        print(\n",
    "            f\"Epoch Train[{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps_train}], Loss: {checkpoint_loss:.4f}\"\n",
    "        )\n",
    "\n",
    "        if len(val_loader.dataset) > 0:\n",
    "            model.eval()\n",
    "            losses = []\n",
    "            tp_tn = 0\n",
    "            for i, pictures in enumerate(val_loader):\n",
    "\n",
    "                images = pictures[\"image\"].to(device)\n",
    "                labels = {\n",
    "                    picture:pictures[\"labels\"][picture].to(device)\n",
    "                    for picture in pictures[\"labels\"]\n",
    "                }\n",
    "\n",
    "                outputs = model(images)\n",
    "                \n",
    "                loss = criterion(loss_func, outputs, labels)\n",
    "\n",
    "                losses.append(loss.item())\n",
    "\n",
    "                tp_tn += calc_results(outputs, labels)\n",
    "\n",
    "            checkpoint_loss = torch.tensor(losses).mean().item()\n",
    "            epoch_losses_test.append(checkpoint_loss)\n",
    "\n",
    "            print(\n",
    "                f\"Epoch Test [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps_test}], Loss: {checkpoint_loss:.4f}\"\n",
    "            )\n",
    "\n",
    "            acc = tp_tn / (3 * len(val_loader.dataset))\n",
    "\n",
    "            if writer is not None:\n",
    "                writer.add_scalar(\"Loss/test\", checkpoint_loss, epoch)\n",
    "\n",
    "                writer.add_scalar(\"Accuracy_class/test\", acc, epoch)\n",
    "\n",
    "            print(f\"Accuracy: {acc}\")\n",
    "\n",
    "        exp_scheduler.step()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def create_submission(\n",
    "                    model, #Model trained.\n",
    "                    sample_sub_path, #Path to the sample submission.\n",
    "                    test_img_path, #Path to the test images.\n",
    "                    dst_path, #Path to store the submission.\n",
    "                    data_mean, #Data mean for z-score norm.\n",
    "                    data_std, #Data std for z-socre norm.\n",
    "                    device #Device to be used in inference\n",
    "):\n",
    "\n",
    "    sample_submission = pd.read_csv(sample_sub_path)\n",
    "\n",
    "    test_img_name_list = sample_submission[\"file\"].to_list()\n",
    "\n",
    "    # create an empty answer dataframe\n",
    "    submission_df = pd.DataFrame(\n",
    "        {\n",
    "            \"file\": test_img_name_list,\n",
    "            \"isLeela\": np.zeros(1000, dtype=int),\n",
    "            \"isFry\": np.zeros(1000, dtype=int),\n",
    "            \"isBender\": np.zeros(1000, dtype=int),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    test_transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(data_mean, data_std),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    model.eval()\n",
    "    for n, row in enumerate(submission_df.iterrows()):\n",
    "\n",
    "        test_img = test_transform(\n",
    "            Image.open(os.path.join(test_img_path, row[1][0])).convert(\"RGB\")\n",
    "        )\n",
    "\n",
    "        test_img = test_img.to(device)\n",
    "        test_img = test_img[None, :, :, :]\n",
    "\n",
    "        outputs = model(test_img)\n",
    "\n",
    "        submission_df.at[n, \"isLeela\"] = torch.max(outputs[\"isLeela\"], 1)[1].item()\n",
    "        submission_df.at[n, \"isFry\"] = torch.max(outputs[\"isFry\"], 1)[1].item()\n",
    "        submission_df.at[n, \"isBender\"] = torch.max(outputs[\"isBender\"], 1)[1].item()\n",
    "\n",
    "    submission_df.to_csv(dst_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('torch-mv')",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
