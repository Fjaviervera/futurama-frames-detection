[
  {
    "objectID": "01_core.html",
    "href": "01_core.html",
    "title": "Train and generate a Submission",
    "section": "",
    "text": "Parameters and Hiper-Parameters\n\n# values for z-score norm\ndata_mean = (0.4180, 0.3998, 0.3396)\ndata_std = (0.2728, 0.2571, 0.2389)\n\n\n# Validation size\nvalidation_size = 0.2\nseed_for_split = 42\n\n# hiper-params\nlr_value = 0.0001\nlr_decay = 0.8\nepochs = 40\ndropout_value = 0.8\nhidden_layer = 3072\nbatch_size = 16\nnetwork_type = \"resnet152\"\n\n# paths\ntrain_data_path = \"data/train_data.csv\"\ntrain_img_path = \"data/train_img\"\nsample_sub_path = \"data/sample_submission.csv\"\ntest_img_path = \"data/test_img/\"\nsub_dst_path = \"my_submission.csv\"\n\n\n\nGet the device to run the training\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f'Using Device:{device}')\n\nUsing Device:cuda\n\n\n\n\nCreate the dataset, transforms and loaders for train\n\nIt is recomended to have 0 validation when we want to generate the final submission\n\n\n#Data augmentation with affine transform,Color Jitter and random erasing.\nrandom_transforms = [\n    transforms.RandomAffine(degrees=(0, 360), scale=(0.25, 0.3)),\n    transforms.RandomAffine(degrees=(0, 360)),\n    transforms.ColorJitter(hue=(-0.5, 0.5)),\n    transforms.RandomErasing(p=0.5, scale=(0.2, 0.5), value=\"random\"),\n]\n\ntrain_transform = transforms.Compose(\n    [\n        transforms.Resize((224, 224)),\n        # transforms.AutoAugment(),\n        transforms.ToTensor(),\n        transforms.RandomChoice(random_transforms),\n        transforms.Normalize(data_mean, data_std),\n    ]\n)\n\n#validation without data augmentation\nval_transform= transforms.Compose(\n    [\n        transforms.Resize((224, 224)),\n        transforms.ToTensor(),\n        transforms.Normalize(data_mean, data_std),\n    ]\n)\n\n#Create two dataset object with the two transformation\nfuturamaDataset_train = FuturamaDataset(train_data_path, train_img_path,train_transform)\nfuturamaDataset_val = FuturamaDataset(train_data_path, train_img_path,val_transform)\n\n# Split into train and val\ntrain_len = int(futuramaDataset_train.__len__()*(1-validation_size))\nval_len = futuramaDataset_train.__len__() - train_len\n\ntrain_set, val_set = torch.utils.data.random_split(\n    futuramaDataset_train,\n    [train_len, val_len],\n    generator=torch.Generator().manual_seed(seed_for_split),\n)\n#assign to the splited val the dataset without dataaugmentation\nval_set.dataset = futuramaDataset_val\n\n\n\n# Create the dataloader for train and test\ntrain_loader = DataLoader(\n    train_set, batch_size=batch_size, shuffle=True, num_workers=8, drop_last=True\n)\nval_loader = DataLoader(\n    val_set, batch_size=batch_size, shuffle=False, num_workers=8, drop_last=False\n)\n\n\nsample = next(iter(train_loader))\n\nprint(f'Train Images example:')\n\nfig, axeslist = plt.subplots(ncols=4, nrows=int(batch_size/4))\nfor ind,transfromed_img in enumerate(sample['image']):\n    axeslist.ravel()[ind].imshow(np.clip( transfromed_img.permute(1, 2, 0),0,1), cmap=plt.gray())\n    # axeslist.ravel()[ind].set_axis_off()\n\nif(len(val_loader)>0):\n    sample = next(iter(val_loader))\n\n    print(f'Validation Images example:')\n\n    fig, axeslist = plt.subplots(ncols=4, nrows=int(batch_size/4))\n    for ind,transfromed_img in enumerate(sample['image']):\n        axeslist.ravel()[ind].imshow(np.clip( transfromed_img.permute(1, 2, 0),0,1), cmap=plt.gray())\n        # axeslist.ravel()[ind].set_axis_off()\n\nTrain Images example:\nValidation Images example:\n\n\n\n\n\n\n\n\n\nmodel = FuturamaResnet(network_type, hidden_layer, dropout_value).to(device)\n\nusing resnet152\n\n\n\n\nTrain the model\n\ntraining(model, device, None, lr_value, lr_decay, epochs, train_loader, val_loader)\n\nAdjusting learning rate of group 0 to 1.0000e-04.\nEpoch Train[1/40], Step [407/407], Loss: 1.8768\nEpoch Test [1/40], Step [102/102], Loss: 1.0355\nAccuracy: 0.866217315196991\nAdjusting learning rate of group 0 to 8.0000e-05.\nEpoch Train[2/40], Step [407/407], Loss: 1.3975\nEpoch Test [2/40], Step [102/102], Loss: 0.5877\nAccuracy: 0.9264705777168274\nAdjusting learning rate of group 0 to 6.4000e-05.\nEpoch Train[3/40], Step [407/407], Loss: 1.0815\nEpoch Test [3/40], Step [102/102], Loss: 0.4535\nAccuracy: 0.9505718946456909\nAdjusting learning rate of group 0 to 5.1200e-05.\nEpoch Train[4/40], Step [407/407], Loss: 0.9160\nEpoch Test [4/40], Step [102/102], Loss: 0.3497\nAccuracy: 0.9577205777168274\nAdjusting learning rate of group 0 to 4.0960e-05.\nEpoch Train[5/40], Step [407/407], Loss: 0.7982\nEpoch Test [5/40], Step [102/102], Loss: 0.3008\nAccuracy: 0.9632353186607361\nAdjusting learning rate of group 0 to 3.2768e-05.\nEpoch Train[6/40], Step [407/407], Loss: 0.7062\nEpoch Test [6/40], Step [102/102], Loss: 0.3045\nAccuracy: 0.9656862616539001\nAdjusting learning rate of group 0 to 2.6214e-05.\nEpoch Train[7/40], Step [407/407], Loss: 0.6705\nEpoch Test [7/40], Step [102/102], Loss: 0.2545\nAccuracy: 0.9709967374801636\nAdjusting learning rate of group 0 to 2.0972e-05.\nEpoch Train[8/40], Step [407/407], Loss: 0.6095\nEpoch Test [8/40], Step [102/102], Loss: 0.2373\nAccuracy: 0.9726307392120361\nAdjusting learning rate of group 0 to 1.6777e-05.\nEpoch Train[9/40], Step [407/407], Loss: 0.5830\nEpoch Test [9/40], Step [102/102], Loss: 0.2299\nAccuracy: 0.9746732115745544\nAdjusting learning rate of group 0 to 1.3422e-05.\nEpoch Train[10/40], Step [407/407], Loss: 0.5421\nEpoch Test [10/40], Step [102/102], Loss: 0.2292\nAccuracy: 0.976307213306427\nAdjusting learning rate of group 0 to 1.0737e-05.\nEpoch Train[11/40], Step [407/407], Loss: 0.5183\nEpoch Test [11/40], Step [102/102], Loss: 0.2152\nAccuracy: 0.9765114784240723\nAdjusting learning rate of group 0 to 8.5899e-06.\nEpoch Train[12/40], Step [407/407], Loss: 0.4753\nEpoch Test [12/40], Step [102/102], Loss: 0.2206\nAccuracy: 0.9781454205513\nAdjusting learning rate of group 0 to 6.8719e-06.\nEpoch Train[13/40], Step [407/407], Loss: 0.4849\nEpoch Test [13/40], Step [102/102], Loss: 0.1997\nAccuracy: 0.9777369499206543\nAdjusting learning rate of group 0 to 5.4976e-06.\nEpoch Train[14/40], Step [407/407], Loss: 0.4650\nEpoch Test [14/40], Step [102/102], Loss: 0.2090\nAccuracy: 0.9787581562995911\nAdjusting learning rate of group 0 to 4.3980e-06.\nEpoch Train[15/40], Step [407/407], Loss: 0.4635\nEpoch Test [15/40], Step [102/102], Loss: 0.1974\nAccuracy: 0.9791666865348816\nAdjusting learning rate of group 0 to 3.5184e-06.\nEpoch Train[16/40], Step [407/407], Loss: 0.4784\nEpoch Test [16/40], Step [102/102], Loss: 0.2001\nAccuracy: 0.9797794222831726\nAdjusting learning rate of group 0 to 2.8147e-06.\nEpoch Train[17/40], Step [407/407], Loss: 0.4583\nEpoch Test [17/40], Step [102/102], Loss: 0.2054\nAccuracy: 0.9787581562995911\nAdjusting learning rate of group 0 to 2.2518e-06.\nEpoch Train[18/40], Step [407/407], Loss: 0.4444\nEpoch Test [18/40], Step [102/102], Loss: 0.2013\nAccuracy: 0.9803921580314636\nAdjusting learning rate of group 0 to 1.8014e-06.\nEpoch Train[19/40], Step [407/407], Loss: 0.4424\nEpoch Test [19/40], Step [102/102], Loss: 0.1955\nAccuracy: 0.9805964231491089\nAdjusting learning rate of group 0 to 1.4412e-06.\nEpoch Train[20/40], Step [407/407], Loss: 0.4439\nEpoch Test [20/40], Step [102/102], Loss: 0.2022\nAccuracy: 0.9795751571655273\nAdjusting learning rate of group 0 to 1.1529e-06.\nEpoch Train[21/40], Step [407/407], Loss: 0.4494\nEpoch Test [21/40], Step [102/102], Loss: 0.1996\nAccuracy: 0.9805964231491089\nAdjusting learning rate of group 0 to 9.2234e-07.\nEpoch Train[22/40], Step [407/407], Loss: 0.4372\nEpoch Test [22/40], Step [102/102], Loss: 0.1952\nAccuracy: 0.9803921580314636\nAdjusting learning rate of group 0 to 7.3787e-07.\nEpoch Train[23/40], Step [407/407], Loss: 0.4272\nEpoch Test [23/40], Step [102/102], Loss: 0.1935\nAccuracy: 0.9805964231491089\nAdjusting learning rate of group 0 to 5.9030e-07.\nEpoch Train[24/40], Step [407/407], Loss: 0.4430\nEpoch Test [24/40], Step [102/102], Loss: 0.1947\nAccuracy: 0.9803921580314636\nAdjusting learning rate of group 0 to 4.7224e-07.\nEpoch Train[25/40], Step [407/407], Loss: 0.4426\nEpoch Test [25/40], Step [102/102], Loss: 0.1968\nAccuracy: 0.9801878929138184\nAdjusting learning rate of group 0 to 3.7779e-07.\nEpoch Train[26/40], Step [407/407], Loss: 0.4329\nEpoch Test [26/40], Step [102/102], Loss: 0.1949\nAccuracy: 0.9805964231491089\nAdjusting learning rate of group 0 to 3.0223e-07.\nEpoch Train[27/40], Step [407/407], Loss: 0.4404\nEpoch Test [27/40], Step [102/102], Loss: 0.1958\nAccuracy: 0.9795751571655273\nAdjusting learning rate of group 0 to 2.4179e-07.\nEpoch Train[28/40], Step [407/407], Loss: 0.4316\nEpoch Test [28/40], Step [102/102], Loss: 0.1952\nAccuracy: 0.9795751571655273\nAdjusting learning rate of group 0 to 1.9343e-07.\nEpoch Train[29/40], Step [407/407], Loss: 0.4280\nEpoch Test [29/40], Step [102/102], Loss: 0.1916\nAccuracy: 0.9801878929138184\nAdjusting learning rate of group 0 to 1.5474e-07.\n\n\nKeyboardInterrupt: \n\n\n\n\nCreate the submission for the challenge\n\nWhen we are satisfied with the hiperparameters chossen, we can generate the submission using the trained model.\n\n\ncreate_submission(\n    model, sample_sub_path, test_img_path, sub_dst_path, data_mean, data_std,device\n)"
  },
  {
    "objectID": "core.html",
    "href": "core.html",
    "title": "Documentation",
    "section": "",
    "text": "FuturamaDataset\n\n FuturamaDataset (data_path:str, train_images_path:str,\n                  transform:torch.nn.modules.module.Module=None)\n\nPytorch Dataset to process the images and labels.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndata_path\nstr\n\npath to the train.csv\n\n\ntrain_images_path\nstr\n\npath to the train images\n\n\ntransform\nModule\nNone\ntransformation\n\n\n\n\n\nFuturamaDataset.__init__\n\n FuturamaDataset.__init__ (data_path:str, train_images_path:str,\n                           transform:torch.nn.modules.module.Module=None)\n\nFuturamaDataset Initialization\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndata_path\nstr\n\npath to the train.csv\n\n\ntrain_images_path\nstr\n\npath to the train images\n\n\ntransform\nModule\nNone\ntransformation\n\n\n\n\n\n\n\nFuturamaResnet\n\n FuturamaResnet (resnet_model, hidden_mlp, drop_out)\n\nA resnet adapted to output 3 classes by 3 mlps.\n\n\n\n\nDetails\n\n\n\n\nresnet_model\n“resnet152” or “resnet34”\n\n\nhidden_mlp\nNumbers of neurons for the hidden layer in each class\n\n\ndrop_out\nDropout in the hidden layer\n\n\n\n\n\nFuturamaResnet.forward\n\n FuturamaResnet.forward (x:torch.FloatTensor)\n\nThe forward pass of the network.\n\n\n\n\nType\nDetails\n\n\n\n\nx\nFloatTensor\ninput tensor\n\n\nReturns\ndict\noutput a dict with the logs\n\n\n\n\n\n\ncalc_results\n\n calc_results (outputs:dict, labels:dict)\n\nTo calculate the accuracy in validation\n\n\n\n\nType\nDetails\n\n\n\n\noutputs\ndict\npredicted classes\n\n\nlabels\ndict\nlabels classes\n\n\nReturns\nFloatTensor\nAccuracy\n\n\n\n\n\n\ncriterion\n\n criterion (loss_func:torch.nn.modules.loss.CrossEntropyLoss,\n            outputs:dict, pictures:list)\n\n\n\n\n\nType\nDetails\n\n\n\n\nloss_func\nCrossEntropyLoss\nLoss function to be used\n\n\noutputs\ndict\nPredicted probs of the classes\n\n\npictures\nlist\nLabels of the classes\n\n\nReturns\nFloatTensor\nLoss\n\n\n\n\n\n\ntraining\n\n training (model:torch.nn.modules.module.Module, device:torch.device,\n           writer:torch.utils.tensorboard.writer.SummaryWriter,\n           lr_rate:float, lr_decay:float, epochs:int,\n           train_loader:torch.utils.data.dataloader.DataLoader,\n           val_loader:torch.utils.data.dataloader.DataLoader)\n\n\n\n\n\nType\nDetails\n\n\n\n\nmodel\nModule\nResnet model to be used.\n\n\ndevice\ndevice\nDevice to be used to train.\n\n\nwriter\nSummaryWriter\nWriter to Tensorboard, can be None\n\n\nlr_rate\nfloat\nLearning rate\n\n\nlr_decay\nfloat\nExponential Decay for the learning rate\n\n\nepochs\nint\nNumber of epochs to train\n\n\ntrain_loader\nDataLoader\nTrain data loader\n\n\nval_loader\nDataLoader\nValidation data loader\n\n\n\n\n\n\ncreate_submission\n\n create_submission (model, sample_sub_path, test_img_path, dst_path,\n                    data_mean, data_std, device)\n\n\n\n\n\nDetails\n\n\n\n\nmodel\nModel trained.\n\n\nsample_sub_path\nPath to the sample submission.\n\n\ntest_img_path\nPath to the test images.\n\n\ndst_path\nPath to store the submission.\n\n\ndata_mean\nData mean for z-score norm.\n\n\ndata_std\nData std for z-socre norm.\n\n\ndevice\nDevice to be used in inference"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Overview",
    "section": "",
    "text": "This file will become your README and also the index of your documentation."
  },
  {
    "objectID": "index.html#install",
    "href": "index.html#install",
    "title": "Overview",
    "section": "Install",
    "text": "Install\npip install your_project_name"
  },
  {
    "objectID": "index.html#how-to-use",
    "href": "index.html#how-to-use",
    "title": "Overview",
    "section": "How to use",
    "text": "How to use\nFill me in please! Don’t forget code examples:\n\n1+1\n\n2"
  }
]